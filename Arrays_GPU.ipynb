{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problema 2\n",
        "Implementar una función que encuentre el valor máximo en un array de números\n",
        "flotantes de gran tamaño (>100 millones de elementos) usando GPU.\n",
        "\n",
        "a. Entrada: Array 1D de números reales (float32)\n",
        "\n",
        "b. Salida: El valor máximo del array\n",
        "\n",
        "c. Comparar rendimiento: CPU vs GPU\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7qzcM1hFx2AL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ-oXlqVstyG",
        "outputId": "497a8d0f-8beb-455d-8d10-eef44a86107f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 27 17:48:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Problema 2\n",
        "# Comprobar que se este usando la GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instalar Cupy\n",
        "!pip install cupy-cuda12x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgoOf09UyeQM",
        "outputId": "bfea55d0-a9d5-47ed-c9a4-cfbdd79d2e66"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (13.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x) (0.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU Versión secuencial (base de comparación)\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Crear array grande en CPU (float32)\n",
        "N = 100_000_000\n",
        "arr_cpu = np.random.rand(N).astype(np.float32)\n",
        "\n",
        "# Medir tiempo CPU\n",
        "t0 = time.perf_counter()\n",
        "max_cpu = np.max(arr_cpu)\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "print(f\"Máximo (CPU): {max_cpu}\")\n",
        "print(f\"Tiempo CPU: {t1 - t0:.4f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMNStWT_ytl4",
        "outputId": "7ef8d339-5312-46d0-b318-2fa6ecf864df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Máximo (CPU): 1.0\n",
            "Tiempo CPU: 0.0342 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU: Versión paralela usando CuPy\n",
        "import cupy as cp\n",
        "import time\n",
        "\n",
        "# Copiar datos a GPU\n",
        "t0 = time.perf_counter()\n",
        "arr_gpu = cp.array(arr_cpu)  # Transferencia host->device\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "# Calcular máximo en GPU\n",
        "t2 = time.perf_counter()\n",
        "max_gpu = cp.max(arr_gpu)\n",
        "cp.cuda.Stream.null.synchronize()  # Esperar que termine\n",
        "t3 = time.perf_counter()\n",
        "\n",
        "# Transferir resultado a CPU\n",
        "max_gpu_host = max_gpu.get()\n",
        "t4 = time.perf_counter()\n",
        "\n",
        "print(f\"Máximo (GPU): {max_gpu_host}\")\n",
        "print(f\"Tiempo transferencia Host→Device: {t1 - t0:.4f} s\")\n",
        "print(f\"Tiempo kernel GPU: {t3 - t2:.4f} s\")\n",
        "print(f\"Tiempo Device→Host: {t4 - t3:.4f} s\")\n",
        "print(f\"Tiempo total GPU: {t4 - t0:.4f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g_L8q6sy28S",
        "outputId": "b3828cc7-a250-4863-c59d-c8e87497cf78"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Máximo (GPU): 1.0\n",
            "Tiempo transferencia Host→Device: 0.6190 s\n",
            "Tiempo kernel GPU: 0.0684 s\n",
            "Tiempo Device→Host: 0.0004 s\n",
            "Tiempo total GPU: 0.6879 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_time = t1 - t0\n",
        "gpu_time_total = t4 - t0\n",
        "speedup = (t1 - t0) / gpu_time_total\n",
        "\n",
        "print(f\"Speedup (CPU/GPU total): {speedup:.2f}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGqb9LF2zTfi",
        "outputId": "7a3c2c01-5ab0-4c29-ab3f-7249e650d919"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speedup (CPU/GPU total): 0.90x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretación de los resultados:\n",
        "\n",
        "Observando los tiempos de ejecución que obtuviste:\n",
        "\n",
        "    Tiempo CPU: 0.0342 segundos\n",
        "    Tiempo total GPU: 0.6879 segundos\n",
        "    Tiempo transferencia Host→Device: 0.6190 segundos\n",
        "    Tiempo kernel GPU: 0.0684 segundos\n",
        "    Tiempo Device→Host: 0.0004 segundos\n",
        "\n",
        "Y el Speedup (CPU/GPU total): 0.90x\n",
        "\n",
        "Esto significa lo siguiente:\n",
        "\n",
        "* Rendimiento Inicial Inesperado: Contrario a lo que se esperaría en muchos casos al usar GPU para tareas computacionalmente intensivas, en este experimento particular, la versión en CPU fue significativamente más rápida (0.0342 segundos) que la versión total en GPU (0.6879 segundos). El speedup de 0.90x confirma esto, indicando que la versión en GPU fue aproximadamente un 90% tan rápida como la versión en CPU (o, visto de otra manera, la CPU fue alrededor de 1.11 veces más rápida).\n",
        "* El Costo de la Transferencia de Datos: La razón principal de que la GPU no haya superado a la CPU en este caso es el tiempo de transferencia de datos entre la memoria principal del sistema (Host) y la memoria de la GPU (Device). Como puedes ver, transferir el array de 100 millones de elementos a la GPU tomó 0.6190 segundos, lo cual es mucho mayor que el tiempo que le tomó a la CPU calcular el máximo directamente (0.0342 segundos).\n",
        "* Eficiencia del Kernel GPU: A pesar del alto costo de la transferencia, el cálculo del máximo en la GPU (el \"Tiempo kernel GPU\") fue muy rápido, tomando solo 0.0684 segundos. Esto demuestra que, una vez que los datos están en la memoria de la GPU, el paralelismo de la GPU es efectivo para esta operación.\n",
        "* Transferencia de Vuelta Rápida: La transferencia del resultado (un único valor máximo) de vuelta a la CPU (Tiempo Device→Host) fue extremadamente rápida (0.0004 segundos), lo cual es esperable ya que es una cantidad mínima de datos.\n",
        "\n",
        "¿Por qué la CPU fue más rápida en este caso?\n",
        "\n",
        "Para que una implementación en GPU sea más rápida que una en CPU, el tiempo ahorrado al ejecutar el cálculo en paralelo en la GPU debe ser mayor que el tiempo adicional que se invierte en transferir los datos entre la CPU y la GPU.\n",
        "\n",
        "En este problema específico de encontrar el valor máximo en un array, la operación np.max() en NumPy (que se ejecuta en la CPU) es extremadamente eficiente y está altamente optimizada. Para un array de 100 millones de elementos, encontrar el máximo es una operación relativamente sencilla que la CPU puede manejar secuencialmente muy rápido.\n",
        "\n",
        "El \"overhead\" de la transferencia de datos a la GPU (que implica copiar todos los 100 millones de elementos) es el factor dominante que hace que el tiempo total en la GPU sea mayor.\n",
        "\n",
        "Consideraciones para un mejor rendimiento en GPU:\n",
        "\n",
        "Para que el uso de la GPU sea ventajoso en problemas de este tipo, generalmente se necesitan dos condiciones:\n",
        "\n",
        "* Operaciones Computacionalmente Muy Intensivas: La operación que se realiza en la GPU debe ser mucho más compleja y consumir más tiempo en la CPU. Encontrar el máximo es relativamente simple. Operaciones como multiplicaciones de matrices grandes, transformadas de Fourier, o simulaciones complejas suelen beneficiarse más del paralelismo de la GPU.\n",
        "* Reutilización de Datos en la GPU: El mayor beneficio de la GPU se obtiene cuando los datos se transfieren una vez a la GPU y se realizan múltiples operaciones (kernels) sobre ellos sin tener que transferirlos de vuelta a la CPU entre cada operación. Si tienes una serie de cálculos que hacer con el mismo array, transferirlo una vez y realizar todas las operaciones en la GPU sería mucho más eficiente.\n",
        "\n",
        "En resumen, los resultados son esperables para este problema particular y tamaño de datos, donde el costo de la transferencia de datos a la GPU supera el ahorro de tiempo en el cálculo del máximo en el kernel. Esto ilustra un principio fundamental del cómputo acelerado por GPU: la transferencia de datos entre Host y Device es costosa y debe minimizarse para obtener un rendimiento superior."
      ],
      "metadata": {
        "id": "U_80lgBT0Nkk"
      }
    }
  ]
}