{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnvyKnYbjwo6",
        "outputId": "94bd5e86-d8c1-4aa2-df89-9fc17b7624df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector size: 250,000,000 elements\n",
            "\n",
            "GPU Name: Tesla T4\n",
            "---\n",
            "Ejecutando en CPU (Secuencial)...\n",
            "Suma Total (CPU): 124999696.0\n",
            "Tiempo CPU (ms): 83.0545\n",
            "\n",
            "Ejecutando en GPU (Paralelo con CUDA)...\n",
            "Suma Total (GPU): 125000120.0\n",
            "Tiempo Cómputo GPU (ms): 84.5776\n",
            "Tiempo Transferencia CPU->GPU (ms): 189.2414\n",
            "\n",
            "==================================================\n",
            "            resultados\n",
            "==================================================\n",
            "Tiempo CPU (Secuencial): 83.05 ms\n",
            "Tiempo GPU (Paralelo):   84.58 ms\n",
            "ACELERACIÓN (Speedup): 0.98x\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "# 1. Definir el tamaño del vector (más de 100 millones de elementos)\n",
        "SIZE = 250_000_000\n",
        "print(f\"Vector size: {SIZE:,} elements\")\n",
        "\n",
        "\n",
        "# 2. Generar el vector de ENTRADA en la CPU (NumPy)\n",
        "vector_cpu = np.random.rand(SIZE).astype(np.float32) ##tipo de dato\n",
        "\n",
        "\n",
        "# Verificar la GPU y CUDA\n",
        "try:\n",
        "   print(f\"\\nGPU Name: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}\")\n",
        "except:\n",
        "   print(\"\\n¡ADVERTENCIA! No se detectó una GPU de NVIDIA o CUDA. ¿Activaste la GPU en el menú 'Entorno de ejecución'?\")\n",
        "\n",
        "\n",
        "print(\"---\")\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# A. Cómputo en CPU (Usando NumPy)\n",
        "# ==========================================================\n",
        "print(\"Ejecutando en CPU (Secuencial)...\")\n",
        "start_cpu = time.perf_counter()\n",
        "# np.sum() es la operación secuencial en la CPU\n",
        "suma_cpu = np.sum(vector_cpu)\n",
        "end_cpu = time.perf_counter()\n",
        "time_cpu = end_cpu - start_cpu\n",
        "\n",
        "\n",
        "print(f\"Suma Total (CPU): {suma_cpu}\")\n",
        "print(f\"Tiempo CPU (ms): {time_cpu * 1000:.4f}\")\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# B. Cómputo en GPU (Usando CuPy / CUDA)\n",
        "# ==========================================================\n",
        "print(\"\\nEjecutando en GPU (Paralelo con CUDA)...\")\n",
        "\n",
        "\n",
        "# **Paso 1: Transferencia de datos CPU -> GPU**\n",
        "#mover vector de la ram a la vram (gpu)\n",
        "start_transfer_to_gpu = time.perf_counter()\n",
        "vector_gpu = cp.asarray(vector_cpu)\n",
        "end_transfer_to_gpu = time.perf_counter()\n",
        "\n",
        "\n",
        "# **Paso 2: Ejecución del Kernel de Reducción**\n",
        "# cp.sum() invoca un Kernel CUDA de reducción optimizado (tipo árbol binario).\n",
        "start_gpu_calc = time.perf_counter()\n",
        "suma_gpu = cp.sum(vector_gpu)\n",
        "# Sincronización: Espera a que la GPU termine todas las operaciones\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "end_gpu_calc = time.perf_counter()\n",
        "time_gpu_calc = end_gpu_calc - start_gpu_calc\n",
        "\n",
        "\n",
        "# **Paso 3: Transferencia de datos GPU -> CPU**\n",
        "#mover el resultado de vuelta a la CPU para imprimirlo.\n",
        "suma_resultado = suma_gpu.get()\n",
        "time_gpu_total = time_gpu_calc #Solo consideramos el tiempo de cómputo para el Speedup puro\n",
        "\n",
        "\n",
        "print(f\"Suma Total (GPU): {suma_resultado}\")\n",
        "print(f\"Tiempo Cómputo GPU (ms): {time_gpu_calc * 1000:.4f}\")\n",
        "print(f\"Tiempo Transferencia CPU->GPU (ms): {(end_transfer_to_gpu - start_transfer_to_gpu) * 1000:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# C. Comparación de Rendimiento (Salida)\n",
        "# ==========================================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"            resultados\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Tiempo CPU (Secuencial): {time_cpu * 1000:.2f} ms\")\n",
        "print(f\"Tiempo GPU (Paralelo):   {time_gpu_total * 1000:.2f} ms\")\n",
        "\n",
        "\n",
        "# El speedup (aceleración) es la razón de los tiempos de ejecución.\n",
        "speedup = time_cpu / time_gpu_total\n",
        "\n",
        "\n",
        "print(f\"ACELERACIÓN (Speedup): {speedup:.2f}x\")\n",
        "print(\"==================================================\")"
      ]
    }
  ]
}